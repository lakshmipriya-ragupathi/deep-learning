{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data \n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n",
      "Information about the dataset \n",
      "None\n",
      "Does dataset contain NULL values?\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "print(f\"Sample data \\n{df.head()}\")\n",
    "print(f\"Information about the dataset \\n{df.info()}\")\n",
    "print(f\"Does dataset contain NULL values?\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping off the ID column since we dont need it\n",
    "df = df.drop(['Id'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object),\n",
       " array([  0,  50, 100]),\n",
       " array([50, 50, 50]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the classes starting indices, and counts\n",
    "classes, classes_index,class_counts = np.unique(df['Species'].to_numpy(), return_index=True, return_counts=True)\n",
    "classes, classes_index, class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the dataset ready \n",
    "#We will consider all the features : :sepal length, speal width, petal length, petal width\n",
    "#we will consider Iris-setos and Iris-versicolor CLASSES \n",
    "#I'm going to use 80% of the data for training and rest of the 20% for testing\n",
    "#creating separate dfs for each class\n",
    "setosa = df.iloc[:classes_index[1]]\n",
    "versicolor = df.iloc[classes_index[1]:classes_index[2]]\n",
    "\n",
    "#separating the class features and class labels, to create a matrix of feature vectors \n",
    "setosa_x = setosa.drop(['Species'], axis = 1)\n",
    "versicolor_x = versicolor.drop(['Species'], axis = 1)\n",
    "\n",
    "\n",
    "#initialising numpy arrays with ones and 0s\n",
    "setosa_y =  np.zeros(50)\n",
    "versicolor_y = np.ones(50)\n",
    "#encoding the sepcies column with setosa as 0 and versicolor as 1 and adding it to the original dataframes for modifying bias during training\n",
    "setosa_x['label'] = setosa_y\n",
    "versicolor_x['label'] = versicolor_y\n",
    "\n",
    "\n",
    "#splitting the data into training and testing \n",
    "ind = int(0.8*class_counts[0])\n",
    "X_train_df = pd.concat([setosa_x.iloc[:ind], versicolor_x.iloc[:ind]], ignore_index=True)\n",
    "X_test_df = pd.concat([setosa_x.iloc[ind:] , versicolor_x.iloc[ind:]], ignore_index=True)\n",
    "y_train_df = pd.concat([setosa_x['label'].iloc[:ind], versicolor_x['label'].iloc[:ind]], ignore_index = True)\n",
    "y_test_df = pd.concat([setosa_x['label'].iloc[ind:], versicolor_x['label'].iloc[ind:]], ignore_index=  True)\n",
    "\n",
    "X_test_df = X_test_df.drop(['label'] , axis = 1)\n",
    "\n",
    "X_train = X_train_df.values\n",
    "X_test = X_test_df.values\n",
    "y_train = y_train_df.values\n",
    "y_test = y_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function / step function \n",
    "def step_activaion(num):\n",
    "    if num >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1 : 2.0\n",
      "Loss for epoch 2 : 2.0\n",
      "Loss for epoch 3 : 1.0\n",
      "Loss for epoch 4 : 0.0\n",
      "number of epochs run: 4\n",
      "modified weight vector after training: [-0.00013 -0.00041  0.00052  0.00022  0.0002 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#single layer single output with step activaion function and min squared error\n",
    "#weight sum and then step activation, squared error is used in gradient descent to modify the weight vector\n",
    "\n",
    "#training\n",
    "#initialising the weights to 0 and bias to 0, creating the modified weight vector a \n",
    "a = np.array([0, 0, 0, 0, 0])\n",
    "\n",
    "#setting the learning rate\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#defining the maximum number of iterations \n",
    "epochs = 500\n",
    "\n",
    "a_old = a\n",
    "\n",
    "number_of_epochs_run = 0\n",
    "#training loop\n",
    "for epoch in range(epochs):\n",
    "    error = 0.0\n",
    "    for i in range(0, len(X_train)):\n",
    "        #computing the y_pred\n",
    "        y_pred = step_activaion(np.dot(a.T , X_train[i]))\n",
    "        #computing mean squared error \n",
    "        error += (y_pred - y_train[i])**2\n",
    "        #updating the weight vector using learning_rate * dE/dWeight * X_i\n",
    "        a = a - learning_rate*(y_pred - y_train[i])*X_train[i]\n",
    "    \n",
    "    #break if modified weights has converged \n",
    "    print(f\"Loss for epoch {epoch + 1} : {error}\")\n",
    "    number_of_epochs_run += 1\n",
    "    if np.array_equal(a_old, a):\n",
    "        break\n",
    "    else:\n",
    "        a_old = a\n",
    "       \n",
    "print(f\"number of epochs run: {number_of_epochs_run}\")\n",
    "print(f\"modified weight vector after training: {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20\n",
      "Number of correctly classified samples: 20\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#testing the model \n",
    "\n",
    "#separating the weights and bias \n",
    "w = a[:4]\n",
    "b = a[4]\n",
    "\n",
    "prediction = []\n",
    "number_of_correctly_classified = 0\n",
    "\n",
    "#testing loop : \n",
    "for j in range(len(X_test)):\n",
    "    y_pred = step_activaion(np.dot(w.T, X_test[j]) + b)\n",
    "    prediction.append(y_pred)\n",
    "    if y_pred == y_test[j]:\n",
    "        number_of_correctly_classified += 1\n",
    "\n",
    "print(f\"Number of samples: {len(X_test)}\")   \n",
    "print(f\"Number of correctly classified samples: {number_of_correctly_classified}\")\n",
    "print(f\"Accuracy: {(number_of_correctly_classified / len(X_test)) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
